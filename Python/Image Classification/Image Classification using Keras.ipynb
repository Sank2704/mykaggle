{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification in a Binary Data Set \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Importing all the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Creating the Sequential Model\n",
    "##Initialising the Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Adding the Convolution Layer\n",
    "##This layer extracts the fetures from the images, \n",
    "##preserves the spatial relationship between pixels by learning image features using small squares of input data\n",
    "## 32- Indiate the Feature detectors(which are individual neurons)\n",
    "## 3,3 - Denotes the shape of the feature detector, 3*3 matrix\n",
    "## input_shape - standardizes all the imgae to the same format, for ease of computation\n",
    "## activation - Activation function to break the linearity\n",
    "    ##https://towardsdatascience.com/activation-functions-and-its-types-which-is-better-a9a5310cc8f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAN\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Pooling Reduces the dimensionality of each feature\n",
    "##Pool_size size of matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Adding a second convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAN\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Using the flatten layer, we will be able to convert the matrix into a linear array\n",
    "##these linear array input only will be abe to input into the nodes of neurl network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Dense is the only actual network layer in that model.\n",
    "##A Dense layer feeds all outputs from the previous layer \n",
    "##to all its neurons, each neuron providing one output to the next layer.\n",
    "##It's the most basic layer in neural networks.\n",
    "##A Dense(10) has ten neurons. A Dense(512) has 512 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAN\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\SAN\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Compiles the Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Reading train data from folders\n",
    "##Param 1 - floder name for Training Data\n",
    "##Param 2 - (target_size) every image will be resized to the specified size\n",
    "##Param 3 - No. of images to be yielded from the generator per batch\n",
    "##Param 4 - No of classes binary as there are two classes, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_set = test_datagen.flow_from_directory('test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##samplesperepoch -- number of saplesto be taken for the modelling, typically the entire sample \n",
    "## Integer. Number of epochs to train the model. \n",
    "##An epoch is an iteration over the entire data provided, \n",
    "##as defined by steps_per_epoch. Note that in conjunction with initial_epoch, epochs is to be understood as \"final epoch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAN\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"\n",
      "C:\\Users\\SAN\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., steps_per_epoch=250, epochs=25, validation_steps=2000)`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "  2/250 [..............................] - ETA: 33:29 - loss: 0.8050 - acc: 0.5312  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAN\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.713435). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  3/250 [..............................] - ETA: 22:49 - loss: 0.7683 - acc: 0.5208"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAN\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.397225). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 929s 4s/step - loss: 0.6788 - acc: 0.5621 - val_loss: 0.6267 - val_acc: 0.6664\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 762s 3s/step - loss: 0.6361 - acc: 0.6395 - val_loss: 0.5820 - val_acc: 0.7074\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 504s 2s/step - loss: 0.5836 - acc: 0.6881 - val_loss: 0.5452 - val_acc: 0.7246\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 494s 2s/step - loss: 0.5450 - acc: 0.7276 - val_loss: 0.5348 - val_acc: 0.7346\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 493s 2s/step - loss: 0.5257 - acc: 0.7303 - val_loss: 0.5321 - val_acc: 0.7320\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 494s 2s/step - loss: 0.5052 - acc: 0.7529 - val_loss: 0.5066 - val_acc: 0.7575\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 494s 2s/step - loss: 0.4836 - acc: 0.7672 - val_loss: 0.5461 - val_acc: 0.7544\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 492s 2s/step - loss: 0.4683 - acc: 0.7744 - val_loss: 0.4899 - val_acc: 0.7675\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 491s 2s/step - loss: 0.4477 - acc: 0.7826 - val_loss: 0.5154 - val_acc: 0.7669\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 493s 2s/step - loss: 0.4345 - acc: 0.7965 - val_loss: 0.4942 - val_acc: 0.7854\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 493s 2s/step - loss: 0.4204 - acc: 0.8025 - val_loss: 0.4826 - val_acc: 0.7821\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 492s 2s/step - loss: 0.4036 - acc: 0.8187 - val_loss: 0.5066 - val_acc: 0.7760\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 780s 3s/step - loss: 0.3857 - acc: 0.8221 - val_loss: 0.4942 - val_acc: 0.7707\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 741s 3s/step - loss: 0.3703 - acc: 0.8316 - val_loss: 0.4897 - val_acc: 0.7794\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 500s 2s/step - loss: 0.3433 - acc: 0.8491 - val_loss: 0.4980 - val_acc: 0.7870\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 491s 2s/step - loss: 0.3305 - acc: 0.8505 - val_loss: 0.5028 - val_acc: 0.7965\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 493s 2s/step - loss: 0.3117 - acc: 0.8674 - val_loss: 0.6277 - val_acc: 0.7446\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 490s 2s/step - loss: 0.2985 - acc: 0.8720 - val_loss: 0.5388 - val_acc: 0.7885\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 490s 2s/step - loss: 0.2771 - acc: 0.8853 - val_loss: 0.5756 - val_acc: 0.7915\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 491s 2s/step - loss: 0.2524 - acc: 0.8961 - val_loss: 0.5781 - val_acc: 0.7816\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 490s 2s/step - loss: 0.2492 - acc: 0.8975 - val_loss: 0.5713 - val_acc: 0.7917\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 492s 2s/step - loss: 0.2280 - acc: 0.9045 - val_loss: 0.5669 - val_acc: 0.8002\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 72281s 289s/step - loss: 0.2257 - acc: 0.9080 - val_loss: 0.5705 - val_acc: 0.7880\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 934s 4s/step - loss: 0.2121 - acc: 0.9133 - val_loss: 0.6011 - val_acc: 0.7959\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 654s 3s/step - loss: 0.1998 - acc: 0.9189 - val_loss: 0.6330 - val_acc: 0.7796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16178bd3828>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                         samples_per_epoch = 8000,\n",
    "                         nb_epoch = 25,\n",
    "                         validation_data = test_set,\n",
    "                         nb_val_samples = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Saving the model so that we can reuse later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-1c63a367a7ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'classifier_Dogs_cats.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m   1086\u001b[0m         \"\"\"\n\u001b[0;32m   1087\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1089\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m         \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "classifier.save('classifier_Dogs_cats.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Predicting on some random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogs\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('download.jpg',target_size = (64,64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] >= 0.5:\n",
    "    prediction = 'dogs'\n",
    "else:\n",
    "    prediction = 'cats'\n",
    "    \n",
    "print(prediction)\n",
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Getting the labels of classes from the traing set,, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'cats', 1: 'dogs'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = training_set.class_indices\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "print(labels)\n",
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_indices=np.argmax(result,axis=1)\n",
    "print(predicted_class_indices)\n",
    "type(predicted_class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cats']\n"
     ]
    }
   ],
   "source": [
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_predctio(filename):\n",
    "    from keras.preprocessing import image\n",
    "    test_image1 = image.load_img(filename,target_size = (64,64))\n",
    "    test_image1 = image.img_to_array(test_image1)\n",
    "    test_image1 = np.expand_dims(test_image1, axis=0)\n",
    "    result1 = classifier.predict(test_image1)\n",
    "    print(result1)\n",
    "    training_set.class_indices\n",
    "    if result1[0][0] >= 0.5:\n",
    "        prediction_prob = 'dogs'\n",
    "    else:\n",
    "        prediction_prob = 'cats'\n",
    "    \n",
    "    print(prediction_prob)\n",
    "    print(result1[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lables_prediction(filename):\n",
    "    test_image = image.load_img(filename,target_size = (64,64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    result = classifier.predict(test_image)\n",
    "    print(result)\n",
    "    predicted_class_indices=np.argmax(result,axis=1)\n",
    "    print(predicted_class_indices)\n",
    "    predictions = labels[result]\n",
    "    print(predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "dogs\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "prob_predctio('C:\\\\Users\\\\SAN\\\\Documents\\\\GitHub\\\\mykaggle\\\\Python\\\\Image Classification\\\\training_set\\\\dogs\\\\dog.4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "[0]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-4a0d3ddba4a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlables_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\Users\\\\SAN\\\\Documents\\\\GitHub\\\\mykaggle\\\\Python\\\\Image Classification\\\\training_set\\\\dogs\\\\dog.4.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-103-526752fc022a>\u001b[0m in \u001b[0;36mlables_prediction\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mpredicted_class_indices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_class_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "lables_prediction('C:\\\\Users\\\\SAN\\\\Documents\\\\GitHub\\\\mykaggle\\\\Python\\\\Image Classification\\\\training_set\\\\dogs\\\\dog.4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]]\n",
      "cats\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "test_image1 = image.load_img('download.jpg',target_size = (64,64))\n",
    "test_image1 = image.img_to_array(test_image1)\n",
    "test_image1 = np.expand_dims(test_image1, axis=0)\n",
    "result1 = classifier.predict_classes(test_image1)\n",
    "print(result1)\n",
    "training_set.class_indices\n",
    "if result1[0][0] >= 0.5:\n",
    "    prediction_prob = 'dogs'\n",
    "else:\n",
    "    prediction_prob = 'cats'\n",
    "    \n",
    "print(prediction_prob)\n",
    "print(result1[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Reading the input image \n",
    "##converting the predicted prob result to int\n",
    "##after converring to int we are able to predict from the lables, as labels is dict type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogs\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('download (11).jpg',target_size = (64,64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = classifier.predict_classes(test_image)\n",
    "sa = int(result[0])\n",
    "predictions = labels[sa]\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('classifier_Dogs_cats.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogs\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('dog.425.jpg',target_size = (64,64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = model.predict_classes(test_image)\n",
    "sa = int(result[0])\n",
    "predictions = labels[sa]\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
