if(name == "Maruti")
break
print(name)
}
}
car_name(Ford)
car_name <- function(x)
{
foreach (name in cars)
{
if(name == "Maruti")
break
print(name)
}
}
cars <- c("Tata","Maruti","Ford","Hyundai")
car_name <- function(x)
{
foreach (name in cars)
{
if(name == "Maruti")
break
print(name)
}
}
cars <- c("Tata","Maruti","Ford","Hyundai")
car_name <- function(x)
{
for (name in cars)
{
if(name == "Maruti")
break
print(name)
}
}
car_name(Maruti)
cars <- c("Tata","Maruti","Ford","Hyundai")
car_name <- function(x)
{
for (x in cars)
{
if(name == "Maruti")
break
print(name)
}
}
car_name(Maruti)
cars <- c("Tata","Maruti","Ford","Hyundai")
car_name <- function(x)
{
for (x in cars)
{
if(x == "Maruti")
break
print(name)
}
}
car_name(Maruti)
cars <- c("Tata","Maruti","Ford","Hyundai")
car_name <- function(x)
{
for (x in cars)
{
if(x == "Maruti")
break
print(x)
}
}
car_name(Maruti)
car_name(Tata)
car_name(Ford)
car_name(Ford)
cars <- c("Tata","Maruti","Ford","Hyundai")
car_name <- function(x)
{
for (name in cars)
{
if(name == "Ford")
break
print(name)
}
}
car_name(Ford)
mtcars
sum(mtcars$mpg>30)
which(mtcars$mpg>30)
mtcars(mtcars$mpg>30)
mtcars[mtcars$mpg>30]
mtcars[mtcars$mpg>30, ]
row.names(mtcars[c(18,20,28,32)], )
row.names(mtcars[c(18,20,28,32), ])
row.names(mtcars[c(18,20,28,32),])
row.names(mtcars[which(mtcars$mpg>30),])
#whch car among all four gear car has max mileage
mtcars(mtcars$gear == 4)
#whch car among all four gear car has max mileage
mtcars[mtcars$gear == 4]
#whch car among all four gear car has max mileage
mtcars[mtcars$gear == 4,]
#whch car among all four gear car has max mileage
mtcars[mtcars$gear == 4,"mpg"]
max(mtcars[mtcars$gear == 4,"mpg"])
which(max(mtcars[mtcars$gear == 4,"mpg"]))
which(mtcars$mpg == max(mtcars[mtcars$gear == 4,"mpg"]))
row.name(mtcars[20,])
row.names(mtcars[20,])
which.max(mtcars$gear == 4)
max(mtcars[mtcars$gear == 4,"mpg"])
which(mtcars$mpg == max(mtcars[mtcars$gear == 4,"mpg"]))
which.max(mtcars$gear == 4,"mpg")
which.max(mtcars[mtcars$gear == 4,"mpg"])
#which car has maximum hors power
which.max(mtcars$hp)
row.names(which.max(mtcars$hp))
row.names(which.max(mtcars$hp))
row.names(mtcars[which.max(mtcars$hp),])
#what is the milage of the car with max horse power
which.max(mtcars$hp)
row.names(mtcars[which.max(mtcars$hp),])
mtcars[which.max(mtcars$hp)]
mtcars[which.max(mtcars$hp),]
mtcars[which.max(mtcars$hp),"mpg"]
#p- Probabiltity (point of cconsideraton, mean, SD, lower.tail T/F)
pnorm(68,75,7)
#p- Probabiltity (point of cconsideraton, mean, SD, lower.tail T/F)
pnorm(68,75,7, T)
pnorm(50,75,7,T)
pnorm(50,75,7,T)*60
pnorm(60,75,7,T)
pnorm(60,75,7,T)*60
60std  = pnorm(60,75,7,T)*60
60std = pnorm(60,75,7,T)*60
lowstd = pnorm(60,75,7,T)*60
highstd = pnorm(80,75,7,F)*60
lowstd-highstd
lowstd+highstd
lowstd = pnorm(60,75,7,lower.tail = T)*60
highstd = pnorm(80,75,7,lower.tail =F)*60
lowstd+highstd
80 - 15
60 - 15
60 - 16
0.5 - lowstd
0.5 - pnorm(60,75,7,lower.tail = T)*60
0.5 - pnorm(60,75,7,lower.tail = T)
highstd = pnorm(80,75,7,lower.tail =F)
lowstd = pnorm(60,75,7,lower.tail = T) # we are calcualting total lower are
lowstd = pnorm(60,75,7,lower.tail = T) # we are calcualting total lower are
highstd = pnorm(80,75,7,lower.tail =F)
lowstd+highstd
(lowstd+highstd)*60
lowstd = pnorm(60,75,7,lower.tail = T) # we are calcualting total lower are
highstd = pnorm(80,75,7,lower.tail =F)
(lowstd+highstd)*60
lowstd = 0.5 - pnorm(60,75,7,lower.tail = T) # we are calcualting total lower are
highstd = 0.5 -  pnorm(80,75,7,lower.tail =F)
(lowstd+highstd)*60
plot(age,sal)
plot(Age,sal)
Age = c(21,22,23,24,25,26)
sal = c(20,21,22,23,24,25)
sta = c(14,12,10,8,6,4)
plot(Age,sal)
cor(Age,sal)
cor(Age,sta)
plot(Age,sal, type="b")
#--------------Linera Regression------------
linreg = lm(sal~Age)
Age = c(21,22,23,24,25,26)
sal = c(8,9,12,17,19,22)
sta = c(14,12,10,8,6,4)
#--------------Linera Regression------------
linreg = lm(sal~Age)
#--------------Linera Regression------------
linreg = lm(sal~Age)
#--------------Linera Regression------------
linreg = lm(sal~Age)
#--------------Linera Regression------------
linreg = lm(sal~Age)
Age = c(21,22,23,24,25,26)
sal = c(8,9,12,17,19,22)
sta = c(14,12,10,8,6,4)
plot(Age,sal, type="b")
cor(Age,sal)
cor(Age,sta)
#--------------Linera Regression------------
linreg = lm(sal~Age)
summary(linreg)
#--------------Linera Regression------------
linreg = lm(sal~Age)
linreg
sal = 3*Age - 56
sal
mtcars
#DV = mpg IV = wt
lnmtcars = lm(mtcars$mpg~mtcar$wt)
#DV = mpg IV = wt
lnmtcars = lm(mtcars$mpg~mtcars$wt)
lnmtcars
mpg= 37.285*wt - 5.344
mpg= 37.285*mycars$wt - 5.344
mpg= 37.285*mtcars$wt - 5.344
mpg
linreg
#DV = mpg IV = wt
lnmtcars = lm(mpg~wt,data = mtcars)
lnmtcars
mpg
#SSE (Sum of Squared Error)
lnmtcars$residuals
sum(lnmtcars$residuals)
sume(lnmtcars$residuals^2)
sum(lnmtcars$residuals^2)
#RMSE
lnmtcars$residuals/32
sqrt(lnmtcars$residuals/32)
sqrt(sum(lnmtcars$residuals/32)
sqrt(sum(lnmtcars$residuals/32)
SSE = sum(lnmtcars$residuals^2)
#RMSE
RMSE = (SSE/nrow(mtcars))^0.5
RMSE
#SSE (Sum of Squared Error)
lnmtcars$residuals
cat(lnf)
cat(SSE)
?cat()
for(i in (1:10) -3)
{
print(c(i,i*i))
}
linreg$coefficients
20CR
20C17
install.packages("combinat")
combn(20,17)
combn(3,2)
library(combinat)
combn(3,2)
dim(combn(20,17))
17/1140
pbinom(17,20,0.5)
pbinom(17,20,0.5,lower.tail = F)
pbinom(17,20,0.5,lower.tail = F)
pbinom(17:20,0.5,lower.tail = F)
pbinom(17:20,20,0.5,lower.tail = F)
sum(pbinom(17:20,20,0.5,lower.tail = F))
mtcars
#DV = mpg IV = wt
lnmtcars = lm(mpg~wt,data = mtcars)
lnmtcars
mpg = -5.344*mtcars$wt + 37.285
mpg
#SSE (Sum of Squared Error)
lnmtcars$residuals
sum(lnmtcars$residuals)
SSE = sum(lnmtcars$residuals^2)
# Linear regression using multiple(two) variables
mtcars
linmulreg = lm(mpg ~ wt+hp+gear, data = mtcars)
summary(linmulreg)
boston
library(boston)
library(Boston)
install.packages("MASS")
library(Boston)
library(MASS)
head(Boston)
lBoston = lm(medv ~ crim+zn+indus+nox, data = Boston)
summary((lBoston))
lBoston = lm(medv ~ crim, data = Boston)
summary((lBoston))
lBoston = lm(medv ~ zn, data = Boston)
summary((lBoston))
lBoston = lm(medv ~ tax, data = Boston)
summary((lBoston))
lBoston = lm(medv ~ chas, data = Boston)
lBoston = lm(medv ~ tax, data = Boston)
summary((lBoston))
lBoston = lm(medv ~ dis, data = Boston)
summary((lBoston))
lBoston = lm(medv ~ ptratio, data = Boston)
summary((lBoston))
lBoston = lm(medv ~ black, data = Boston)
summary((lBoston))
lBoston = lm(medv ~ lstat, data = Boston)
summary((lBoston))
lBoston = lm(medv ~ dis, data = Boston)
summary((lBoston))
cor(Boston$medv)
cor(Boston)
lBoston = lm(medv ~ rm, data = Boston)
summary((lBoston))
cor(Boston)
lBoston = lm(medv ~ rm+lstat, data = Boston)
summary((lBoston))
lBoston = lm(medv ~ rm+lstat+ptratio, data = Boston)
summary((lBoston))
#SSE, RMSE, MAPE
SSE = sum(lBoston$residuals^2)
RMSE = (SSE/nrow(Boston))^0.5
SSE = sum(lBoston$residuals^2)
RMSE = (SSE/nrow(Boston))^0.5
#SSE, RMSE, MAPE
lBoston$residuals
SSE = sum(lBoston$residuals^2)
RMSE = (SSE/nrow(Boston))^0.5
MAPE = sum(lBoston$residuals/Boston$medv)/nrow(Boston)
MAPE
MAPE = sum(abs(lBoston$residuals/Boston$medv))/nrow(Boston)
MAPE
mean(Boston$medv)
(Boston$medv - mean(Boston$medv))^2
sum((Boston$medv - mean(Boston$medv))^2)
TSS = sum((Boston$medv - mean(Boston$medv))^2)
R2 = 1- (SSE/TSS)
R2
#SSE, RMSE, MAPE
lBoston$residuals
lBoston$residuals
SSE = sum(lBoston$residuals^2)
RMSE = (SSE/nrow(Boston))^0.5
MAPE = sum(abs(lBoston$residuals/Boston$medv))/nrow(Boston)
MAPE
TSS = sum((Boston$medv - mean(Boston$medv))^2)
R2 = 1- (SSE/TSS)
R2
MAPE = sum(abs(lBoston$residuals/Boston$medv))/nrow(Boston)
MAPE
#SSE, RMSE, MAPE
lBoston$residuals
summary((lBoston))
cor(Boston)
library(MASS) # Load the pacakage
cor(Boston)
data("iris")
head(iris)
install.packages("rpart")
install.packages("rpart.plot")
library(rpart)
library(rpart.plot)
#Model Building
tree = rpart(Species ~ ., data=iris)
prp(tree)
library(MASS)
head(Boston)
reg_tree = rpart(medv ~ ., data = Boston)
prp)reg_tree
prp(reg_tree)
iris
head(iris)
distance = dist(iris[,1:4]) #selecting all rows and only the first four column, coz we are in consedration of only  columns
head(distance)
class(distance)
clust = hclust(distance, method = "ward.D")
plot(clust)
my_clusters = cutree(clust,3)
my_clusters
table(iris$Species,my_clusters)
data(iris)
head(iris)
k_means = kmeans(iris[,-5])
k_means = kmeans(iris[,-5],3)
k_means
k_means$cluster
table(k_means)
table(k_means$cluster)
table(iris$Species, k_means$cluster)
names(k_means)
k_means$cluster
k_means$centers
k_means$totss
k_means$withinss #Within Sum of Squares
k_means$tot.withinss
k_means$betweenss #Between Sum Of Squares
k_means$size  #Gives the size of each one
#Silhoutte Ploy
d= c()
#Binomal Theorem
#pbinom(success, total throws, probability of each)
pbinom(17,20,0.5, lower.tail = FALSE)
#Binomal Theorem
#pbinom(success, total throws, probability of each)
pbinom(17:20,20,0.5, lower.tail = FALSE)
sum(pbinom(17:20,20,0.5, lower.tail = FALSE))
#Running Linear Regression using mtcars
head(mtcars)
linreg=lm(mpg~wt+hp+gear)
linreg=lm(mpg~wt+hp+gear, data = mtcars)
summary(linreg)
#Linear Regression in Boston
library(MASS)
head(Boston)
linreg=lm(medv~., data = Boston)
summary(linreg)
linreg=lm(medv~crim+zn+chas+nox+rm+dis+rad+tax+ptratio+black+lstat, data = Boston)
summary(linreg)
linreg=lm(medv~zn+chas+nox+rm+dis+rad+tax+ptratio+black+lstat, data = Boston)
summary(linreg)
linreg=lm(medv~zn+chas+nox+rm+dis+rad+ptratio+black+lstat, data = Boston)
summary(linreg)
linreg=lm(medv~crim+zn+chas+nox+rm+dis+rad+ptratio+black+lstat, data = Boston)
summary(linreg)
linreg=lm(medv~crim+zn+chas+nox+rm+dis+ptratio+black+lstat, data = Boston)
summary(linreg)
SSE = linreg$residuals
SSE = sum(linreg$residuals^2)
SSE
RMSE = (SSE/nrow(Boston))^0.5
RMSE
MAPE = sum(abs(linreg$residuals/Boston$medv))/nrow(Boston)
MAPE
#TSS Total Sum of Squares
avg=mean(Boston$medv)
TSS = sum((Boston$medv-medv)^2)
TSS = sum((Boston$medv-avg)^2)
R2 = 1-(SSE/TSS)
R2
data(iris)
head(irsi)
head(iris)
library(rpart)
library(rpar)
library(rpart.plot)
dt = rpart(Species ~ . , data = iris)
prp(dt)
data(iris)
head(iris)
library(rpart)
library(rpart.plot)
dt = rpart(Species ~ . , data = iris)
prp(dt)
data(iris)
head(iris)
library(rpart)
library(rpart.plot)
dt = rpart(Species ~ . , data = iris)
prp(dt)
data(iris)
head(iris)
library(rpart)
library(rpart.plot)
dt = rpart(Species ~ . , data = iris)
prp(dt)
hoohhohohohohhhh
print(wrg)
print("wo")
head(Boston)
?Boston
library(MASS)
head(Boston)
reg_tree = rpart(medv ~ . , data = Boston)
prp(reg_tree)
library(randomForest)
rf = randomForest(Species ~ . , data= iris)
pred=predict(rf)
table(iris$Species, pred)
rf = randomForest(Species ~ . , data= iris,ntree=1000, nodesize=5, mtry=2)
pred=predict(rf)
table(iris$Species, pred)
tree = rpart(Species~., data = iris, minbucket = 5)
pred1 = predit(tree)
library(rpart)
library(rpart.plot)
tree = rpart(Species~., data = iris, minbucket = 5)
pred1 = predict(tree)
table(iris$Species, pred1)
tree = rpart(Species~., data = iris, minbucket = 5,method="class")
pred1 = predict(tree)
table(iris$Species, pred1)
tree = rpart(Species~., data = iris, minbucket = 5,type="class")
pred1 = predict(tree)
table(iris$Species, pred1)
tree = rpart(Species~., data = iris, minbucket = 5,method="response")
pred1 = predict(tree)
table(iris$Species, pred1)
tree = rpart(Species~., data = iris, minbucket = 5,method="class")
pred1 = predict(tree)
table(iris$Species, pred1)
pred1 = predict(tree,type="class")
table(iris$Species, pred1[,1])
prp(tree)
table(iris$Species, pred1)
table(iris$Species, pred)
#Usupervised Learning
head(iris)
iris[,c(1,2,4)]
distances = dist(iris[,1:4])
clust = hclust(distances)
plot(clust)
distances = dist(iris[,1:4])
clust = hclust(distances)
clust = hclust(distances, method = "ward.D")
plot(clust)
install.packages("readr")
setwd("G:\\Personnal\\CTS\\Imarticus\\R Code\\Kaggle\\Digit Recognizer")
train = read.csv("train.csv")
test = read.csv("test.csv")
# Create a 28*28 matrix with pixel color values
m = matrix(unlist(train[10,-1]),nrow = 28,byrow = T)
# Plot that matrix
image(m,col=grey.colors(255))
rotate <- function(x) t(apply(x, 2, rev)) # reverses (rotates the matrix)
par(mfrow=c(2,3))
lapply(1:6,
function(x) image(
rotate(matrix(unlist(train[x,-1]),nrow = 28,byrow = T)),
col=grey.colors(255),
xlab=train[x,1]
)
)
par(mfrow=c(1,1)) # set plot options back to default
